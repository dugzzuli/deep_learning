# 【1】"深度学习笔记.py"
0.梯度下降法可以运用在很多算法中，比如logistic回归；即并不是只要有梯度下降就要想到反向传播，而是只要有反向传播，就会有梯度下降法，并不是充要条件     
1.在卷积神经网络中,经过卷积层或池化层后还剩多少像素        
2.关于权重初始化是否可为0的问题         
3.关于梯度下降法      
4.激活函数---------【摘自吴恩达深度学习视频】    
5.神经网络与logistic回归对比         
6.反向传播 ----很精辟，不需要繁琐的推导        
7.参数VS超参数        
# 【2】"logistic回归知识点.py"---(摘自吴恩达深度学习视频)              
1.疑问     
2.向量化      
3.np.dot()内积函数的用法         
4.broadcasting 广播        
5.logistic损失函数与成本函数 推导              
# 【3】"logistic回归_源代码.py"        
1.logistic回归的吴恩达视频源代码        
2.向量化与for循环：2个for->1个for->0个for      
3.shape和reshape      


