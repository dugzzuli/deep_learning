# deeplearning
####在卷积神经网络中，关于经过卷积层或者池化层后还剩多少像素的问题：这里不考虑边缘填充的问题，只讲方法帮助理解以便笔试中快速计算。【图片尺寸-卷积核尺寸(或者池化尺寸)】/步长+1=卷积或者池化后的尺寸....最后加1是因为比如1,2有两个数，2-1+1=2。。。
例如:图片尺寸100*100，卷积核尺寸5*5，[按照卷积核窗口的最后一个像素为标准移动，一直移动到图片的最后一个像素]     
   【步长为1时】，经过卷积层后的像素大小计算过程为，由于卷积核为5*5,那么图片的前5*5个像素是第1个点，然后向右移动一步则第2个到第6个像素的5*5个像素变成第2个点，以此类推，则从第5个像素移动到第100个像素共有100-5+1=96个，即卷积层后图片变为了96*96，这是步长为1的情况。        
   【步长为2时】：是第5,7,9,11,...,99。总共移动了(99-5)/2+1=48次，即图片由100*100变为了48*48了。这里没考虑第100个像素，因为步长为2，最后只剩一列了，组合不了5*5，只有4*5.填充什么的我不考虑。     
   【步长为3时】，按照上面的方法就行了。5,8,11,...,98。。。核窗口的最后一个像素总共移动了(98-5)/3+1=32次，卷积或者池化后的尺寸为32*32     
对于书中讲的池化层，比如2*2的池化窗口并没有重叠的，那是因为池化的步长为2.如果池化窗口为3*3,步长为3，那也是没有重叠的.

####关于权重初始化是否可为0的问题      
【1.神经网络】：隐藏层的每个神经元分别学习到不同的特征，如果权重全部初始化为0，那么各层的每个神经元都学习相同的特征，就相当于每层神经元都只有一个神经元，因此神经网络不能权重初始化为0.    
【2.单层感知机】只有一个神经元，他的权重可初始化为0      
【3.线性回归模型】相当于单层感知机，其权重也可以初始化为0


###关于梯度下降法        
【1】比如[x1 x2] = meshgrid(-5:5, -5:5);y=x1.^2+x2.^2  surf(x1,x2,y); 可把该代码在matlab中运行看图形是什么样。       
这个表达式的图形就是一个把四个角吊起来的网。梯度为(2*x1,2*x2),该图的负梯度方向是平行于x1 x2平面并指向里面的方向，并不是该点的切线方向，也不是某个指向地面的容易让人混淆的切线.       
【2】但是对于只有一个变量的比如 y=x.^2,其梯度为2*x，即其负梯度方向为-2*x，即是其导数。对于线性函数比如y=x,其梯度就是其斜率。      
【3】#只需要记住，负梯度方向是使函数值减少最快的方向，但是是供变量迭代相加减的，并不是供函数值相加减的。只需要用变量加上负梯度方向就是变量的下一个迭代值:w1=w0-α*dy/dw0,α是步长,dy/dw0是在w0处的梯度方向。     
【4】在多变量时候还容易想通，对于一元二次函数，对变量迭代时，由于根据图像来推导，总是觉得梯度方向是跟变量迭代的加减扯不上关系的，不知道为什么要用变量加上步长乘以负梯度。似懂非懂，那就不管了吧，记住多变量的就好
