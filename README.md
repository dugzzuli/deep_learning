# "深度学习笔记.py"
0.梯度下降法可以运用在很多算法中，比如logistic回归；即并不是只要有梯度下降就要想到反向传播，而是只要有反向传播，就会有梯度下降法，并不是充要条件     
1.在卷积神经网络中,经过卷积层或池化层后还剩多少像素        
2.关于权重初始化是否可为0的问题         
3.关于梯度下降法       
# "logistic回归知识点.py"--------(摘自吴恩达深度学习视频)              
1.疑问     
2.向量化     
3.np.dot()内积函数的用法     
4.broadcasting 广播     
5.logistic损失函数与成本函数 推导          
# "logistic回归_源代码.py"文件讲了 向量化与for循环,dot(),shape,reshape。以及logistic回归的吴恩达视频源代码       

