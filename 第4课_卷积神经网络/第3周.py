# 第3.3课内容
滑动窗口目标检测法：
	首先选定一个特定大小的窗口，将这个窗口（从图片左上角开始）输入卷积网络，卷积网络开始进行预测，即判断该窗口内有没有汽车，
	然后将窗口稍向右滑动，并输入给卷积网络，检测这一个窗口内有没有汽车。即每次输入进卷积网络的只是这张大图片的某个小窗口范围内
	的图片。依次重复操作直到这个窗口滑过图像的每一个角落，对每个窗口位置的图片按0和1进行分类（即有或没有目标）。
	为了滑动得更快，可以选用较大的步幅。
	也可以选取更大的窗口进行滑动。
	
滑动窗口目标检测法有很明显的缺点，就是计算成本。因为你在图片中剪切出太多小方块，卷积网络要一个一个地处理。如果选用的步幅很大，
显然会减少输入卷积神经网络的窗口个数，但是粗粒度可能会影响性能。反之，如果采用小粒度或小步幅，传递给卷积网络的小窗口会特别多，
这意味着超高的计算成本。

所以在神经网络兴起之前，人们通常采用更简单的分类器进行对象检测，比如简单的线性分类器。至于误差，因为每个分类器的计算成本都很低，
它只是一个线性函数，所以滑动窗口目标检测算法表现很好。然而，卷积网络运行单个分类任务的成本却高得多，像这样滑动窗口太慢了。除非
采用超细力度或极小步幅，否则无法准确定位图片中的对象。不过，庆幸的是，计算成本问题已经有了很好的解决方案，大大提高了在卷积层上
应用滑动窗口目标检测器的效率。

----------------------------------------------------------------------------------------------------------------------------------
#第3.4课内容

把全连接层转化成卷积层：
比如 使用5*5的过滤器，在全连接层来实现卷积，若全连接层的前一层图像是5*5*16，全连接层有400个节点就使用400个5*5*16的过滤器对图像
进行卷积得到输出维度为1*1*400，我们不再把它看做一个含有400个节点的集合，而是一个1*1*400地输出层。从数学角度看，他和全连接层是一
样的，因为这400个节点中的每一个节点都有一个5*5*16维度的过滤器，所以每个值都是上一层这些5*5*16激活值经过某个任意线性函数的输出结果。
不管原来有几个全连接层，每个全连接层都可以这样转化成卷积层。

#【疑问】
为什么要把全连接层转化成卷积层呢？把图片拉成一个向量有什么不好？那么多过滤器，过滤器的参数都是一个个的慢慢训练数据得到的吗？
难道进行卷积速度会特别快？

#在卷积层上应用滑动窗口算法的内容，它提高了整个算法的效率。这种算法有个缺点，就是边界框的位置可能不够准确。
假设输入给卷积网络的图片大小是14*14*3，测试集图片是16*16*3，按照上节课的滑动窗口检测法，是先从左上角滑动，步幅为2，这样就有
四个子集。结果发现这四次卷积操作中的很多计算都是重复的。滑动窗口的卷积应用，使得卷积网络在这四次操作过程中很多计算都是重复的。
最终，在输出层这2*2的四个子方块中，蓝色的是图像左上部分14*14的输出。

所以该卷积操作的原理是：
我们不需把输入图片分割成四个子集分别执行前向传播，而是把它们作为一张图片输入给卷积网络进行计算，其中的公有区域可以共享很多计算。

我们不用依靠连续的卷积操作来识别图片中的汽车，我们可以对大小为28*28的整张图片进行卷积操作，一次得到所有预测值。

----------------------------------------------------------------------------------------------------------------------------------
# 第3.5课内容
# 指定边界框
# 有一个能得到更精确的边界框的算法是：YOLO算法
YOLO意思是，你只看一次。YOLO的方法是：比如，你的输入图像是100*100，然后在图像上放一个网格，为了介绍简单一点，我用3*3网格，在实际
实现的时候会用更精细的网格，可能是19*19。基本思路是，使用图像分类和定位算法（前面视频介绍过得算法），然后将算法逐一应用到9个格子上。
更具体一点，你需要这样定义训练标签：即对于9个格子中的每一个，制定一个标签y,y是8维向量，[是否对象Pc,对象中心横坐标bx、纵坐标bw，对象
宽bw、高bh，有没有其他对象（三个对象：汽车c1、人c2、摩托车c3）]。对于有两个对象的整张图片，YOLO算法的方法是：取两个对象的中心坐标，
然后将这个对象分配给包含对象中心点的格子，即使有时候中心格子同时有两辆车的一部分。对于某个格子，都有一个目标标签（因为是训练集，并非
正在预测，所以有目标标签）。其中bx,by,bh,bw是指定边界框位置。最后，因为目标输出是3*3*8，所以总的输出尺寸也是3*3*8，即输出层的3*3*8
的9个向量(8维向量)对应于分割为3*3块的各块，由于3*3块，则每块最终输出的向量是由8维向量组成。
至于输入到输出的中间网络结构，就是卷积层池化层等等构成的，还是用反向传播训练网络。
这个算法的优点在于：神经网络可以输出精确的边界框，所以测试的时候，你做的事，喂入输入图像x，然后正向传播，直到你得到这个输出y，然后对
这里的3*3位置对应的9个输出向量中的元素分别标为0或1以及边框的中心坐标和宽高。只要每个格子中对象数目没有超过1个，这个算法应该是没问题的。
1个格子中存在多个对象的问题，我们稍后再讨论。

这种方法比滑动窗口法优点就是不会受到滑动窗口法分类器的步长大小限制，其次这是一个卷积实现，你并没有在3*3网格上跑9次算法，或者19*19的网
格上跑361次，相反，这次是单次卷积实现，你使用了一个卷积网络。有很多共享计算步骤，在处理这3*3计算中很多计算步骤是共享的。所以这个算法
的效率很高。实际上他的运行速度非常快，可以达到实时识别。

对于编码这个对象边界框时，有一个约定就是，该对象所在的格子左上角坐标为（0,0），右下角坐标为（1,1），对象中心横坐标bx是网格长度的百分
比，对象中心纵坐标by是网格高度的百分比，对象宽度bw是网格的宽度的百分比，高度bh是网格长度的百分比。



如果上面的看懂了，就不用看下面这段话了。
对于不使用滑窗法检测整张图片中的对象，方法是把整张图片分割为3*3或者19*19块，然后对每一块都进行卷积，但不是依次卷积，而是最终得到了
比如你把图片分割了3*3块，最终就得到了3*3*n的最终输出，输出层的3*3*n的9个向量(n维向量)对应于分割为3*3块的各块，由于3*3块，则每块最终
输出的向量是由8维向量[是否对象,对象中心横、纵坐标，对象宽、高，有没有其他对象（三个对象：汽车、人、摩托车）]组成。
这样就不需要使用滑窗法依次滑动输入卷积神经网络了来进行识别了。

----------------------------------------------------------------------------------------------------------------------------------
# 第3.6课内容
# 交并比（IoU:intersection over union）
# 交并比 用来评价你的对象定位算法是否精准，衡量了两个边界框重叠的相对大小。
在对象检测算法中，你希望同时还能够定位对象（不光检测到对象，还要定位对象）。所以如果实际的边界框和你的算法给出的边界框不一致，那么该
怎样评价这个算法的好坏呢？
交并比函数做的就是：计算两个边界框交集和并集（面积）之比.
一般约定，在计算机检测任务中，如果IoU>=0.5，就说检测正确。如果预测器和实际边界框完美重叠，IoU就是1，因为交集等于并集。但是一般来说，
只要IoU>=0.5，那么结果是可以接受的。你也可以设置为0.6或者更高。所以这是衡量定位精确度的一种方式，你只需要统计算法正确地检测和定位对象
的次数，判断对象定位是否准确。

# 我有一个问题：他的实际边框怎么得到的呢？靠人工标注起来，然后再计算吗？如果这样那也太麻烦了吧？


----------------------------------------------------------------------------------------------------------------------------------
# 第3.6课内容
# 非极大值抑制

