【0】总结一下，在机器学习中，我们通常将样本分成训练集、验证集和测试集三部分。数据集规模相对较小的，适用传统的划分比例60%,20%,20%；
	数据规模较大的，验证集和测试集可以占到数据总量的20%或10%以下.例如100万条数据，1万条作验证集，1万条作测试集，训练集占98%。
	验证集是用来评估不同的模型；测试集是对最终所选定的神经网络系统做出【无偏评估】。如果不需要无偏评估，也可以不设置测试集。
	如果只有验证集，没有测试集，我们要做的是，在训练集上训练，尝试不同的模型框架，在验证集上评估这些模型，然后迭代并选出适用的模型。
	因为验证集中已经涵盖测试集数据，其不再提供无偏性能估计。
	在机器学习中，如果只有一个训练集和一个验证集，而没有独立的测试集，则验证集被称为测试集。不过在实际应用中，人们只是把测试集当成
	简单交叉验证集使用，并没有完全实现该术语的功能，因为他们把验证集数据过度拟合到了测试集中。如果某团队跟你说他们只设置了一个训练集
	和一个测试集，我会很谨慎，心想他们是不是真的有训练验证集，因为他们把验证集数据过度拟合到了测试集中，让这些团队改变叫法，
	改称其为"训练验证集"，而不是"训练测试集"可能不太容易，即便我认为在专业用词上更准确。实际上，如果你不需要无偏评估算法性能，
	那么这样是ok的。
	
【1】深度学习的另一个趋势是，越来越多的人在训练集和测试集分布不匹配的请情况下进行训练，假设你要构建一个用户可以上传大量图片的应用程序，
	目的是找出并呈现所有的猫咪图片，训练集可能是从网上下载的猫咪图片，而验证集和测试集是用户在这个应用上上传的猫咪的图片。
	就是说，训练集可能是从网上抓下来的图片，分辨率很高，而验证集和测试集使用户上传的图片（可能是手机随意拍摄的），分辨率很低，比较模糊。
	这两类数据有所不同。根据经验，我建议大家 要确保验证集和测试集的数据来自同一分布。
	
【2】偏差和方差   bias/variance
	偏差高，不能很好的拟合数据集，欠拟合    举的例子图是二分类logistic
	分类器方差较高，数据过度拟合，过拟合    举的例子图是神经网络过拟合分类的图
	
	训练集误差和验证集误差  train set error  /   dev set error
	(1)训练集误差(1%)低，验证集误差(11%)高，则称之为高方差
	(2)训练集数据的拟合度不高，就是数据欠拟合，就可以说这种算法偏差比较高；
		相反，他对于验证集产生的结果却是合理的，验证集中的错误率(16%)只比训练集的错误率(15)多1%，所以这种算法偏差高.
	(3)训练集错误率是15%，偏差相当高，但是验证集的评估结果更糟糕，错误率达到30%。
		这种情况下，我会认为这种算法偏差高，因为它在训练集上结果不理想，方差也很高，这是方差偏差都很高的情况。
	(4)训练集错误率为0.5%，验证集错误率为1%，则方差和偏差都很低。
			
	一般来说，最优误差也被称为贝叶斯误差
	# 如果最优误差或贝叶斯误差非常高，比如15%，15%的错误率对训练集来说是非常合理的，偏差不高，方差也非常低。【感觉这句话有问题，我没理解】

	先检查偏差，再检查方差：
	(1)如果偏差高，(欠拟合)，就试一下:1.选择一个新网络(比如含有更多隐藏层或者隐藏单元的网络)。2.花费更多的时间来训练网络，
		或者尝试更先进的优化算法。    不过采用规模更大的网络通常会有所帮助，延长训练时间不一定有用，但也没什么坏处。
		训练学习算法时，需要不断尝试这些方法，直到解决掉偏差问题，这是最低标准，反复尝试，直到可以拟合数据为止。
		至少能够拟合训练集。如果网络足够大，通常可以很好的拟合训练集。
	(2)当偏差降低到可接受的数值，检查一下方差有没有问题，为了评估方差，我们要查看验证集性能；
		如果方差高，最好的解决方法就是【采用更多数据】。但有时候，我们无法获得更多数据，我们也可以尝试通过【正则化】来减少过拟合。
	(3)反复各种尝试，直到找到一个低偏差，低方差的框架，这样你就成功了。
	
	有两点需要注意：
	(1)高偏差和高方差是两种不同的情况，我们后续要尝试的方法也可能完全不同。我们通常会用训练验证集来诊断算法是否存在偏差
		或方差问题。，然后根据结果选择尝试部分方法。
		举个例子，如果算法存在高偏差问题，准备更多训练数据其实什么用都没有。所以大家要清楚到底是高方差还是高偏差问题。
		明确这一点有助于我们选出最有效的方法。
	(2)在机器学习的初期阶段，关于偏差方差权衡的探讨屡见不鲜。原因是我们可以尝试的方法有很多，可以增加偏差，减少方差。
		但是在深度学习的早期阶段，我们没有太多工具可以做到只减少偏差或方差，却不影响到另一个。但是在当前的深度学习和大数据时代，
		只要持续训练一个更大的网络，只要准备了更多数据，那么也并非只有这两种情况。
		只要正则适度，通常构建一个更大的网络便可以在不影响方差的同时，减少偏差。而采用更多数据通常可以在不过多影响偏差的同时减少方差。
		这两步实际要做的工作是训练网络、选择网络或者准备更多数据，现在我们有工具可以做到在只减少偏差的同时，不对另一方产生过多不良影响。
		我觉得这就是深度学习对监督式学习大有裨益的一个重要原因。也是我们不用太过关注如何平衡偏差和方差的一个重要原因。
		