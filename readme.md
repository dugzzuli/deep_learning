# 【1】"深度学习笔记.py"
0.梯度下降法可以运用在很多算法中，比如logistic回归；即并不是只要有梯度下降就要想到反向传播，而是只要有反向传播，就会有梯度下降法，并不是充要条件     
1.在卷积神经网络中,经过卷积层或池化层后还剩多少像素        
2.关于权重初始化是否可为0的问题         
3.关于梯度下降法      
4.激活函数---------【摘自吴恩达深度学习视频】    
5.神经网络与logistic回归对比         
6.反向传播 ----很精辟，不需要繁琐的推导        
7.参数VS超参数        
8.logistic回归与softmax的成本函数
9.epoch、 iteration和batchsize的区别