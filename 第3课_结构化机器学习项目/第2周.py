【1】误差分析
	总结一下，进行误差分析，你应该找一组错误里子，可能在你的开发集里、或者测试集里，观察所无标记的例子，看看假阳性和假阴性，
	统计属于不同错误类型的错误数量。在这个过程中，你可能会得到启发，归纳出新的误差类型，就像我们看到的那样，如果你过了一遍
	错误例子，然后说，天，有这么多Instagram（一款图像分享应用）滤镜，或Snapchat(照片分享平台)，这些滤镜干扰了我的分类器，
	你就可以在途中新建一个错误类型。总之，通过统计不同标记类型占总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你构
	思新优化方向的灵感。
	
	例如，识别猫的算法中，误差率为10%。如果在100个错误标记的开发集例子中，有5个是狗。这意味着在典型的100个出错的例子中，即
	使你完全解决了狗的问题，你也只能修正这100个错误中的5个。或者换句话说，如果你只有5%的错误是狗图片，那么你在狗的问题上花
	了很多时间，那么你最多只能希望你的误差从10%下降到9.5% (10%-10%*5%=9.5%)。误差下降了5%，那就是10%下降到9.5%。
	

	事实证明，深度学习算法对于【训练集】中的随机误差是相当鲁棒的。只要你的标记出错的例子，只要这些错误例子离随机误差不太远，有
	时可能做标记的人没有注意，或者不小心按错键了。如果误差足够随机，那么放着这些误差不管可能也没问题，而不要花费太多时间修
	复它们。当然你浏览以下训练集，检查一下这些标签，并修正它们也没什么害处。只要总数据集足够大，实际误差可能不会太高。
	
	但是深度学习对系统性的错误就没那么鲁棒了。比如说，如果做标记的人一直把白色的狗标记成猫，那就成问题了。因为你的分类器学
	习之后，会把所有白色的狗都分类为猫，但是随机误差或近似随机误差对于大多数深度学习算法来说，不成问题。
	
	上面是针对【训练集】中标记出错来说明的。那么如果是【开发集和测试集】中有这些标记出错的例子呢？
	如果你担心开发集和测试集中标记出错的例子带来的影响，一般建议你在误差分析时，添加一个额外的列，这样你也可以统计标签Y错误的
	例子数。比如说，你可能统计对100个标记出错的例子的影响，所以你会找到100个例子，其中你的分类器的输出和开发集的标签不一致，
	有时对于其中的少数例子，你的分类器输出和标签不同，是因为标签错了，而不是你的分类器出错。在这个例子中，你发现标记的人漏了
	背景里的一只猫，所以那里打个勾，来表示例子98标签出错了，也许这张图实际上是猫的样子，而不是一只真正的猫，也许你希望标记Y
	=0，而不是Y=1，然后再在那里打个勾。当你统计出其他错误类型的百分比后，就像我们在之前的视频中看到的那样，你还可以统计因为
	标签错误所占的百分比，你的开发集里的Y值是错误的，这就解释了，为什么你的学习算法做出和数据集里的标记不一样的预测。
	
	所以现在问题是，是否值得修正这6%标记出错的例子。我的建议是，如果这些标记错误，严重影响了你在开发集上评估算法的能力，那么
	就应该花时间修正错误的标签。但是如果它们没有严重影响到你用开发集评估成本偏差的能力，那么就不应该花宝贵的时间去处理。
	我建议你看三个数字来确定是否值得去人工修正标记出错的数据：
	整体的开发集误差:之前的视频中，我们说也许我们的系统达到了90%的整体准确度，所以有10%误差。那么你应该看看错误标记引起的
	错误的数量或者百分比。所以在这种情况下，6%的错误来自标记出错，所以10%的6%就是0.6%，也许你应该看看其他原因导致的错误。如
	果你的开发集上有10%的错误，其中0.6%是因为标记出错，剩下的占9.4%是其他原因导致的，比如把狗误认为猫。所以在这种情况下，我
	说有9.4%误差需要集中精力修正，而标记出错导致的错误是总体错误的一小部分而已。所以如果你一定要这么做，你也可以手工修正各种
	错误标签，但也许这并不是当下最重要的任务。
	
	我们再看另一个例子，假设你在学习问题上取得了很大进展，所以误差不再是10%了，假设你把误差降到了2%，但总体错误中的0.6%还是标
	记出错导致的。所以现在，如果你想检查一组标记出错的开发集图片，开发集数据有2%标记错误了，那么其中很大部分0.6%/(2%)，实际上
	变成30%标签而不是6%标签了，有那么多错误例子其实是因为标记出错导致的，所以现在其他原因导致的错误是1.4%，当测得的那么大一部
	分的错误都是开发集标记出错导致的，那似乎修正开发集里的错误标签似乎更有价值。如果你还记得设立开发集的目标的话，开发集的主要
	目的是，你希望用它来从两个分类器A和B中选择一个。所以当你测试两个分类器A和B时，在开发集上有一个2.1%误差，另一个有1.9%误差，
	但是你不能在信任开发集了，因为它无法告诉你，这个分类器是否比这个好，因为0.6%的误差是标记出错导致的。那么现在你就有很好的
	理由去修正开发集里的错误标签。因为在右边这个例子中，标记出错对算法错误的整体评估标准有严重的影响，而左边的例子中，标记出
	错对你算法影响的百分比还是相对较小的。
	
	现在如果你决定要去修正开发集数据，手动检查标签，并尝试修正一些标签，这里还有一些额外的方针和原则需要考虑。
	(1)首先我鼓励你，不管用什么修正手段，都要同时作用到开发集和测试集上。
	我们之前讲过为什么开发集和测试集要来自同样的分布，开发及确定了你的目标，当你集中目标后，你希望算法能够推广到测试集上，这样
	你的团队能够更高效的在来自同一分布的开发集和测试集上迭代。如果你打算修正开发集上的部分数据，那么最好也对测试集做同样的修正
	，以确保他们来自相同的分布。所以我们雇佣了一个人来仔细检查这些标签，但必须同时检查开发集和测试集。
	
	(2)其次，我强烈建议你要考虑，同时检验算法判断正确和判断错误的例子。
	要检查算法出错的例子很容易，只需要看看哪些例子是否需要修正，但还有可能有些例子算法没判断对，那些也需要修正。
	如果你只修正算法出错的例子，你对算法的偏差估计可能会变大，这会让你的算法有一点不公平的优势，我们就需要再次检查出错的例子，
	但也需要再次检查做对的例子，因为算法有可能因为运气好，把某个东西判断对了。在那个特例里，修正那些标签可能会让算法从判断对
	变成判断错。 
	这第二点不是很容易做，所以通常不会这么做。通常不会这么做的原因是，如果你的分类器很准确，那么判断错的次数比判断正确的次数
	要少得多。所以如果你的分类器有98%的准确度，那么就有2%出错，98%都是对的。所以更容易检查2%数据上的标签。然而检查98%数据上的
	标签需要花的时间长得多，所以通常不这么做，但也是要考虑到的。
	
	(3)最后，如果你进入到一个开发集和测试集去修正这里的部分标签,你可能会，也可能不会对训练集做同样的事情。在之前的视频中讲过，
	修正训练集中的标签其实相对没那么重要。你可能决定只修正开发集和测试集中的标签，因为他们通常比训练集小得多，你可能不想把所
	有额外的精力投入到修正大得多的训练集中的标签。
	开发集和测试集来自同样的分布非常重要，而如果训练集来自稍微不同的分布，通常这是意见很合理的事情。
	
	吴恩达的建议：
	在构造实际系统时，通常需要更多的人工误差分析，更多的人类见解来架构这些系统，尽管深度学习的研究人员不愿意承认这点。
	第二，不知道为什么，我看一些工程师和研究人员不愿意亲自去看这些例子，坐下来看100或者几百个例子来统计错误数量，也许做这些事
	很无聊，但我经常亲自这么做。当我带领一个机器学习团队时，我想知道它犯的错误，我会亲自去看这些数据，尝试和一部分错误作斗争。
	我想，就因为花了这几分钟或者几个小时去亲自统计数据，真的可以帮你找到需要优先处理的任务，我发现花时间亲自检查数据非常值得，
	所以我强烈建议你们考虑这么去做。
	
【2】处理训练集和测试集存在差异的方法
	在深度学习时代，越来越多的团队都用来自和开发集和测试集分布不同的数据来训练。这里有一些微妙的地方，一些最佳做法，来处理训
	练集和测试集存在差异的情况。
	方案1：不推荐此方案，比较差。
		200000个在网页上下载的图片+10000个手机用户上传的图片
		将两个集合的图片混合在一起，即210k张图片，205k张图片做训练集，2500张图片做开发集，2500张图片做测试集
		则2500张开发集图片中，平均而言，有2500*（200k/210k）=2381张图片来自网页下载，只有119张图片来自手机用户。要记住设立开发集
		的目的是，告诉你的团队去瞄准的目标，而你瞄准目标的方式，你的大部分精力都用在优化来自网页下载的图片，这其实并不是你想要的。
		所以我真的不建议使用这个方案，因为这样设立开发及，就是告诉你的团队，针对不同于你实际关心的数据分布去优化。
	方案2：训练集，比如说还是205k张图片，其中200k来自网页下载，再加上5k张来自手机上传的的图片。然后对于开发集和测试集都是手机图，
		即开发集就是2500张来自手机应用的图片，测试集也是2500张来自手机应用的图片。
		这样划分数据集的好处在于：现在你瞄准的目标就是你想要处理的目标，你告诉你的团队，我的开发集包含的数据全部来自手机上传，
		这是你真正关心的图片分布。我们试试搭建一个学习系统，让系统在处理手机上传图片分布时效果良好。缺点在于，当然了，现在你的
		训练集分布和你的开发集和测试集分布不一样。事实证明，这样把数据分成训练、开发和测试集，在长期能给你带来更好的系统性能。
		
		
	训练-开发集(training-dev set)：和训练集是同一分布，但是不是用来训练的。
	当（开发集、测试集）和训练集来自不同分布，就从训练集中分出一部分作为训练-开发集。
	即开发集和测试集来自同一分布，训练集和训练-开发集来自同一分布。但不同的地方在于，现在你只在训练集训练你的神经网络，你不会让神
	经网络在训练-开发集上跑反向传播。为了进行误差分析，你应该做的是看看分类器在训练集上的误差、训练-开发集上的误差以及开发集上的误差。
	
	比如说，这个例子中，训练误差是1%，训练-开发集上的误差是9%，开发集误差是10%。你就可以从这里得到结论，当你从训练数据变到训练-开发集
	数据时，误差真的上升了很多，而训练数据和训练-开发数据的差异在于，你的神经网络能看到第一部分数据(分割之后的训练集)，并直接在上面
	做了训练，但没有在训练-开发集上直接训练。这就告诉你，算法存在方差问题，因为训练-开发集的误差是在和训练集来自同一分布的数据中测
	得的。所以你知道，尽管你的神经网络在训练集中表现良好，但无法泛化到来自相同分布的训练-开发集里，即他无法泛化到来自同一分布但以前
	没见过的数据中。所以在这个例子中，我们确实有一个方差问题。
	
	看一个不同的例子，假设训练误差为1%，训练-开发误差为1.5%，但当你开始处理开发集时，误差上升到10%，现在你的方差问题就很小了，因为
	当你从训练数据转到没见过的训练-开发集数据，误差只上升了一点点；但当你转到开发集时，误差就大大上升了，所以这是数据不匹配的问题。
	因为你的学习算法没有直接在训练-开发集或者开发集训练过，但是这两个数据集来自不同的分布，它在训练-开发集上做的很好，但在开发集上
	做的不好，所以总之你的算法擅长处理和你关心的数据不同的分布，我们称之为数据不匹配问题。
	
	再看一个例子，训练误差10%，训练-开发集误差11%，开发集误差12%。记住人类水平或贝叶斯误差大概是0%。如果你得到了这种等级的
	表现，那就真的存在偏差问题了，即可避免偏差，因为算法做的比人类水平差很多。
	
	最后一个例子，训练误差10%，训练-开发集误差11%，开发集误差20%。那么其实有两个问题：第一，可避免偏差相当高，因为你在训练集上没有
	做得很好，而人类水平接近0%误差，但你的算法在训练集上误差为10%，（训练集到训练-开发集）方差似乎很小，但是数据不匹配问题（从训练-开
	发集到开发集）很大。所以对这个例子，如果你有很大的偏差或者可避免偏差问题，还有数据不匹配问题。
	
	看四个数据：人类水平误差，训练集误差，训练-开发集误差，开发集误差。
	从上面四个数据你可以知道，可避免偏差，方差，数据不匹配问题各自有多大。技术上，你还可以再加入一个数字，就是测试集表现，我们写成测
	试集误差，你不应该在测试集上开发，因为你不希望对测试集过拟合。开发集误差到测试集误差的差距说明你对开发集过拟合的程度。所以如果开
	发集表现和测试集表现有很大差距，那么你可能对开发集过拟合了，所以也许你需要一个更大的开发集。要记住，你的开发集和测试集来自同一分
	布，所以如果这里存在很大差距的话，如果算法在开发集上做的很好，比测试集好的多，那么你就可能对开发集过拟合了，如果是这样，那么你就
	需要收集更多开发集数据。

【3】如何解决数据不匹配问题？
	其中讲到了：先做误差分析。有个方法叫【人工数据合成】。太长我没做笔记。
	
【4】迁移学习
	迁移学习什么时候是有意义呢？
	迁移学习起作用的场合是，对迁移来源问题，你有很多数据，但对迁移目标问题，你没有那么多数据。
	例如，假设图像识别任务中你有一百万个样本，你可以学习低层特征，即可以在神经网络的前面几层学到如何识别很多有用的特征，但是对于放射
	科任务，也许你只有100个样本，所以你的放射学诊断问题数据很少，也许只有100次x射线扫描。所以你从图像识别训练中学到的很多知识可以迁
	移，，并且真正帮助你加强放射科识别任务的性能，即使你的放射科数据很少。
	
	例如，对于语音识别，也许你已经用10000小时数据训练过你的语音识别系统，所以你从这10000小时数据学到了很多人类声音的特征，这数据量其
	实很多了，但对于触发字检测，也许你只有1小时数据，所以这数据太小，不能用来拟合很多参数，所以在这种情况下，预先学到很多人类声音的
	特征、人类语言的组成部分等等知识,可以帮你建立一个很好的唤醒字检测器,即使你的数据集相对较小,对于唤醒任务来说，至少数据集要小得多。
	
	对于这两种情况下，你从数据量很多的问题，迁移到数据量相对较小的问题。然后反过来的话，迁移学习可能就没没有意义了。比如说，如果你的
	放射科数据更多，那么这100张猫狗或者随机物体的图片肯定不会有太大帮助，因为来自猫狗识别任务中，每一张图的价值肯定不如一张x射线扫描
	图有价值，对于建立良好的放射科诊断系统而言是这样。 同样，如果你用10小时数据训练一个语音识别系统，然后你实际上有10个小时甚至更多，
	比如50个小时唤醒字检测的数据，你知道迁移学习有可能会有帮助，也可能不会，也许吧这10小时数据迁移学习不会有太大坏处，但是你也别指望
	会得到有意义的增益。
	
	总结一下，什么时候迁移学习是有意义的呢？
	(1)如果你想从任务A学习，并迁移一些知识到任务B，那么当任务A和任务B都有同样的输入x时，迁移学习是有意义的。第一个例子中，A和B的输入
	   都是图像，第二个例子中，两者输入都是音频。
	(2)当任务A的数据比任务B的数据多得多时，迁移学习意义更大。所有这些假设的前提都是，你希望提高任务B的性能。因为任务B每个数据更有价
	   值，对任务B来说，通常任务A的数据量必须大得多才有帮助。因为任务B里单个样本的价值比任务A单个样本价值更大。
	(3)然后如果你觉得任务A的低层次特征可以帮助任务B的学习，那迁移学习更有意义一些。而在前面的例子中，也许学习图像识别交给系统足够多
	   图像相关的知识，让它可以进行放射科诊断。也许学习语音识别教给系统足够多人类语言信息，能帮助你开发字或唤醒字检测器。

【5】多任务学习
	在迁移学习中，你的步骤是串行的，你从任务A学到知识，然后迁移到任务B。在多任务学习中，你是同时开始学习的，试图让单个神经网络同时
	做几件事情，然后希望这里每个任务都能帮到其它所有任务。
	
	例如，假设你在研发无人驾驶车辆，那么你的无人驾驶车可能需要同时检测不同的物体，比如检测行人、车辆、停车标志、交通灯以及各种其他
	东西。比如某个图像中，有停车标志、车，但是没有行人和交通灯。如果输入图像是x^(i),那么标签就不再是一个标签y^(i)，而是有4个标签，
	即标签是一个向量：
						物体  y^(i)
						行人   0
						  车   1
					停车标志   1
					  交通灯   0
	如果你尝试检测其他物体，那么y^(i)的维数会更高。现在我们就先用4个，所以y^(i)是个4*1向量。
	如果从整体来看所有训练集m个样本标签Y=[y^(1) y^(2) y^(3) ... y^(m)]，那么矩阵Y就是4*m矩阵。而从前的例子，标签y是单实数时，Y就是
	1*m矩阵。
	现在你可以做的是，训练一个神经网络，来预测这些y值。神经网络的输出层有4个节点，每个节点输出为0或1，每个节点分别表示有没有行人、车
	辆、停车标志、交通灯。
	要训练这个网络，你现在需要定义神经网络的损失函数。对于整个训练集的平均损失：
	Loss=1/m *∑∑ L(y_j^(i),y_j(i))   
	y_j^(i)表示第i个样本的第j个特征的预测值
	第一个求和符从i=1到i=m,第二个求和符从j=1到j=4
	标志L指的是logistic损失L(y_j^(i),y_j(i))=-y_j(i)*logy_j^(i)-(1-y_j(i))*log(1-y_j^(i))
	
	和之前分类猫的例子的主要区别在于，现在你要对j=1到4求和。这与softmax的主要区别在于，softmax将单个标签分配给单个样本，而本例这张图
	可以有很多不同的标签。所以不是说每张图都只是一张行人图片、汽车图片、停车标志图片或者交通灯图片，你要知道的是照片中是否有行人或汽
	车标志或交通灯，多个物体可能同时出现在一张图里。即你不是只给图片一个标签，而是需要遍历不同类型，然后看看每个类型有没有出现在图片中。
	
	如果你训练了一个神经网络，试图最小化这个成本函数Loss，你做的就是多任务学习，因为你现在做的是建立单个神经网络，观察每张图，然后
	解决4个问题，系统试图告诉你，每张图里面有没有这4个物体。
	另外你也可以训练4个不同的的神经网络，而不是训练一个网络做4件事。但是神经网络的一些早期特征，在识别不同物体时都会用到，然后你会
	发现，训练一个神经网络做4件事情会比训练4个完全独立的神经网络分别做4件事情性能要更好，这就是多任务学习的力量。
	
	到目前为止，我是这么描述算法的，即每张图都有全部标签。事实证明，多任务学习也可以处理图像只有部分物理被标记的情况。所以第一个训练
	样本，只知道有人，别的没标记。类似这种情况下，在Loss中我们就只对带0和1标签的j值求和，别的项忽略。
	
	多任务学习什么时候有意义呢？
	当三件事为真时，他就是有意义的。
	(1)如果你训练的一组任务，可以共用低层次特征。对于无人驾驶的例子，同时识别交通灯，汽车和行人是有道理的，这些物体有相似的特征，也
	   许能帮你识别停车标志，因为这些都是道路上的特征。
	(2)这个准则没那么绝对，所以不一定是对的，但我从很多成功的多任务学习案例中看到，如果每个任务的数据量很接近，你还记得迁移学习时，
	   你从任务A学到知识，然后迁移到任务B。所以任务A有一百万个样本，但任务B只有1000个样本，那么你从这100万个样本学到的知识，真的可
	   以帮你增强对更小数据集任务B的训练。那么多任务学习又怎么样呢？
	   在多任务学习中，你通常有更多任务而不仅仅是两个，所以也许你有，以前我们有4个任务，但比如说你要完成100个任务，而你要做多任务学
	   习，尝试同时识别100种不同类型的物体。你可能会发现，每个任务大概有1000个样本。所以如果你专注加强单个任务的性能，比如我们专注
	   加强第100个任务的表现，我们用A100表示。如果你试图单独去做这最后的一个任务，你只有1000个样本去训练这个任务，这是100项任务之一。
	   而通过在其它99项任务的训练，这99个加起来一共有99000个样本，这可能大幅提升算法性能，可以提供很多知识来增强这第100个任务的性能。
	   不然对于任务A100，只有1000个样本的训练集，效果可能会很差。如果有对称性，这其它99个任务，也许能提供一些数据，或提供一些知识，来
	   帮到这100个任务中的每一个任务。
	   所以这第二点不是绝对正确的准则，但我通常会看到的是，如果你专注于单项任务，如果你想要从多任务学习得到很大性能提升，那么其他任务
	   加起来，必须要有比单个任务大得多的数据量。要满足这个条件，其中一种方法是，比如上面这个例子这样，如果每个任务中的数据量很相近，
	   但关键在于，如果单个任务你已经有1000个样本了，那么对于所有其他任务，你最好有超过1000个样本，这样其他任务的知识才能帮你改善这个
	   任务的性能。	
	(3)当你可以训练一个足够大的神经网络，同时做好所有的工作。所以多任务学习的替代方法是，为每个任务训练一个单独的神经网络，所以，不是
	   训练单个神经网络同时处理行人、汽车、停车标志和交通灯检测。你可以训练一个用于行人检测的神经网络、一个用于汽车检测的神经网络、一
	   个用于停车标志检测的神经网络和一个用于交通信号灯检测的神经网络。
	   
	多任务学习会降低性能的唯一情况和训练单个神经网络相比性能更弱的情况，就是你的神经网络还不够大。但如果你可以训练一个足够大的神经网络，
	那么多任务学习肯定不会或者很少会降低性能。我们都希望它可以提高性能，比单独训练神经网络来单独完成各个任务性能要更好。
	
	在实践中，多任务学习的使用频率要低于迁移学习，我看到很多迁移学习的应用，你需要解决一个问题，但你的训练数据很少，所以你需要先找一个
	数据很多的相关问题，来预先学习。并将知识前一代这个新问题上。但多任务学习比较少见。就是你需要同时处理很多任务，都要做好，你可以同时
	训练所有这些任务，也许计算机视觉是一个例子，在物体检测中，我们看到更多使用多任务学习的应用。其中一个神经网络尝试检测一大堆物体比分
	别检测不同的神经网络检测物体更好。但是平均来说，目前迁移学习使用频率更高。但两者都可以成为你的强力工具。
	
	总结一下，多任务学习能让你训练一个神经网络来执行许多任务，这可以给你更高的性能，比单独完成各个任务更高的性能。但要注意，实际上迁移
	学习比多任务学习使用频率更高，我觉得这是【因为你很难找到那么多相似且数据量对等的任务，可以用单一神经网络训练】，但是在计算机视觉领
	域，【物体检测】这个例子是最显著的例外情况。

【6】端到端的深度学习
	深度学习中最令人振奋的最新动态之一，就是端到端深度学习的兴起。
	以前有一些数据处理系统或者学习系统，他们需要多个阶段的处理，那么端到端深度学习，就是忽略所有这些不同的阶段，用单个神经网络代替它。
	即直接学习出从系统的一端（输入x）到系统的另一端（输出y）。
	以语音识别为例，你的目标是输入x，比如说一段音频，然后把它映射到一个输出y，即这段音频的听写文本。所以传统上，语音识别需要很多阶段
	的处理：首先你会提取一些特征，一些手工设计的音频特征，在提取出一些低层次特征之后，你可以应用机器学习算法，在音频片段中找到音位。
	所以音位是声音的基本单位，然后你讲音位串在一起构成独立的词，再将词春起来构成音频片段的听写文本。
	
	所以和这种有很多阶段的流水线相比，端到端深度学习做的是，你训练一个巨大的神经网络，输入就是一段音频，输出直接就是听写文本。
	随着端到端深度学习系统表现开始更好，有些花了大量时间或者整个职业生涯设计出流水线各个步骤或其它构件的研究员很难接受。而端到端深度
	学习就只需要把训练集拿过来，直接学习到了x和y之间的函数映射，直接绕过了其中很多步骤。
	
	当使用端对端时数据量不是特别大的时候，例如门禁系统，可以划分为两个问题解决，每个问题实际上简单的多，并且两个子任务的训练数据都很多。
	具体来说，有很多数据可以用于人脸识别训练，框出人脸位置，这是任务一；对于任务2，进行人脸匹配，也有很多数据可以用，比如企业拥有数百万
	甚至数亿张人脸照片。相反，如果你想一步到位，这样x,y的数据就少得多。因为你没有足够多的数据去解决这个端到端学习问题，但是却有足够多
	的数据来解决子问题1和子问题2。实际上，把这个分成两个子问题，比纯粹的端到端深度学习方法能达到更好的表现。
	
	端到端的优点：
	(1)如果你有足够多的x,y数据，那么不管x到y最适合的函数映射是什么，如果你训练一个足够大的神经网络，希望这个神经网络能自己搞清楚。
	   而使用纯机器学习方法，直接从x到y去训练的神经网络可能更能够捕获数据中的任何统计信息，而不是被迫引入人类的成见。
	(2)端到端的方法第二个好处就是，所需手工设计的组件更少。你不需要话太多时间去手工设计功能，手工设计这些中间表示方式。
	
	端到端的缺点：
	(1)首先，它可能需要大量的是数据。要直接学到这个x到y的映射，你可能需要大量x,y数据。你可以收集大量子任务数据，比如人脸识别，我们可以
	   收集很多数据，用来分辨图像中的人脸，但是对于整个端到端任务，可能只有更少的数据可用。
	(2)它排除了可能有用的手工设计组件。机器学习研究人员一般都很鄙视手工设计的东西，但如果你没有很多数据，你的学习算法就没法从很小的
	   训练集数据中获得洞察力。所以手工设计组件在这种情况，可能是把人类知识直接注入算法的途径，这总不是一件坏事。我觉得学习算法有两
	   个主要的知识来源，一个是数据，另一个是你手工设计的任何东西(可能是组件、功能或者其他东西)。所以当你有成吨数据时，手工设计的东
	   西就不太重要了；但是当你没有太多的数据时，构造一个精心设计的系统，实际上可以将人类对这个问题的很多认识直接注入到问题里，进入
	   算法里，应该挺有帮助的。所以端到端深度学习的弊端之一是，它把可能有用的人工设计的组件排除在外了，精心设计的人工组件可能非常有
	   用，但它们也有可能真的伤害到你的算法表现。
	