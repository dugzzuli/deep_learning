

【1】正交化
	正交意味着互成90度。设计出正交化的控制装置，调整某一(或一组)参数，不会影响到另一(或一组)参数。
	1.首先，你通常必须确保，至少系统在训练集上得到的结果不错，所以训练集上的表现必须通过某种评估达到能接受的程度；
	2.在训练集上表现不错之后，你就希望系统能在开发集上有的表现；
	3.然后你希望系统在测试集上也有好的表现；
	4.在最后，你希望系统在测试集上，系统的成本函数在实际使用中表现令人满意。比如说，你希望这些猫图片应用的用户满意。
【2】单实数评估指标
	查准率(精确率)：在你的分类器标为猫的例子中，有多少真的是猫。如果查准率是95%，这意味着你的分类器说这图有猫的时候，有95%的
			几率真的是猫。
	查全率(召回率)：对于所有真猫的图片，你的分类器正确识别出了多少百分比。实际为猫的图片中，有多少被系统识别出来。
	
	事实证明，查准率和查全率之间往往需要折中，两个指标都要顾及到。你希望得到的效果是，当你的分类器说，某个东西是猫的时候，
	有很大机会它真的是一只猫。但对于所有是猫的图片，你也希望系统能够将大部分分类为猫。所以用查准率和查全率来评估分类器，是
	比较合理的。但使用查准率和查全率作为评估指标的时候，有个问题：如果分类器A在查全率上表现更好，分类器B在查准率上表现更好，
	你就无法判断哪个分类器更好。如果你尝试了很多不同想法，很多不同的超参数，你希望能够快速试验不仅仅是两个分类器，也许是
	十几个分类器，快速选出最好的那个，这样你可以从那里出发再迭代。如果有两个评估指标，就很难去快速地二选一或者十选一。所以
	我并不推荐使用两个评估指标查准率和查全率来选择一个分类器。而是结合查准率和查全率的标准方法，即所谓的F1分数，F1分数的细节
	并不重要，但非正式的，你可以认为这是查准率P和查全率R的平均值；正式来看，F1定义为：F1=2/(1/p+1/R)
	在数学中，这个函数叫做“查准率P和查全率R的调和平均数”。你可以将它堪称是某种查准率和查全率的平均值，只不过你算的不是直接的
	算术平均，而是用上面这个公式的调和均值。这个指标在权衡查准率和查全率时有一些优势。
	
	很多机器学习团队就是这样：有一个定义明确的开发集，用来测量查准率和查全率，再加上这样一个单实数评估指标，能让你快速判断
	哪个算法更好。所以有这样一个开发集，加上一个单实数评估指标，你的迭代速度肯定会很快，它可以加速改进机器学习算法的迭代过程。
	看另一个例子，即当好几个算法对不同国家的误差率也不同时，可以平均每个算法的各个国家的误差率，选取平均误差率最小的算法作为
	最优的算法。
【3】训练集、开发集、测试集划分
	设立训练集、开发集、测试集的方式，大大影响了你或你的团队在建立机器学习应用方面取得进展的速度。
	如何设立开发集和测试集？    
	dev集也叫作开发集，有时称为保留交叉验证集。从后面讲的来看，开发集就是验证集，但他没有这么说过，验证集是validation set。
	机器学习中的工作流程是，你尝试很多思路，用训练集训练不同的模型，然后开发集来评估不同的思路，然后选择一个，然后不断迭代
	去改善开发集的性能，直到最后你可以得到一个令你满意的成本，然后你在用测试集去评估。
	
	需要保证让测试集和开发集来自同一分布。
	设立你的开发集，加上一个单实数评估指标，这就像是定下目标，然后告诉你的团队，那就是你要瞄准的靶心。因为你一旦建立了这样
	的开发集和指标，团队就可以快速迭代，尝试不同的想法、跑实验，可以很快地使用开发集和指标去评估不同分类器，然后尝试选出最
	好的那个。所以机器学习团队一般都很擅长使用不同方法去逼近目标，然后不断携带，不断逼近靶心。
	
	所以设立开发集和测试集时，如果开发集和测试集数据不来自同一分布，存在一个问题，你的团队可能会花上几个月时间在开发集上迭
	代优化，结果发现，当你们最终在测试集上测试系统时，来自这四个国家的数据和开发集里面的数据可能差异很大。所以你会发现花了
	那么多个月的时间去针对开发集优化，但是最后在测试集上的表现却不佳。所以，如果你的开发集和测试集来自不同的分布，就像你设
	了一个目标，让你的团队花几个月尝试逼近靶心，结果在几个月的工作之后发现不合适。
	方法：将所有数据随机洗牌，放入开发集和测试集，所以开发集和测试集来自同一分布，这分布就是你的所有数据混在一起。
	
	设立训练集的方式，会影响你逼近那个目标有多快。
	以前的经验法则是：当数据集不多时，可以选择7:3来分给训练集，开发集和测试集。但是在现代大数据时代，流行的是，把大量数据
	分到训练集，然后少量数据分到开发集和测试集，特别是当你有一个非常大的数据集时。以前的经验法则是为了确保开发集足够大，能
	够达到它的目的，就是帮你评估不同的想法，然后选出哪个算法更好。测试集的目的是评估你最终的成本偏差，你只需要设立足够大的
	测试集，可以用来评估就行了，可能只需要远远小于总体数量的30%。
	
	训练集用来训练模型，可以训练好几个模型，比如神经网络的结构不一样，或者激活函数，或者别的参数不一样；
	验证集用于模型的选择，即从训练好的几个模型中选择对验证集有最小预测误差的模型；
	测试集用于对最终方法的评估，即检验最终选择最优的模型的性能如何，主要是测试训练好的模型的分辨能力（识别率等）
	
	训练集作用：估计模型，学习样本数据集，通过匹配一些参数来建立一个分类器。建立一种分类的方式，主要是用来训练模型的。

	验证集作用：确定网络结构或者控制模型复杂程度的参数。对学习出来的模型，调整分类器的参数，如在神经网络中选择隐藏单元数。

	测试集作用：检验最终选择最优的模型的性能如何。主要是测试训练好的模型的分辨能力（识别率等）
	
	K折交叉验证： http://sofasofa.io/forum_main_post.php?postid=1000354&  K折交叉验证淡化了验证集和测试集的概念。如果只是说验证集，
	而不是说交叉验证，那么就是上面所述；如果说交叉验证，那么就是本网页所述。这是我的理解。
【4】什么时候该改变开发/测试集和指标？
	算法A：3% error   但是会把一些色情图片误分类为猫
	算法B: 5% error	  不会把色情图片误分类为猫
	虽然算法A误差率更小，但是却会存在色情图片被推送，这是绝对不能容许的。你和用户就会倾向于选择算法B。但是评估指标和开发集
	却会选算法A。因此当这种情况发生时，即你的评估指标无法正确衡量算法之间的优劣排序时，你就应该改变评估指标了，或者改变开发
	集或测试集。
	
	假如之前的误差率公式为：
		Error=1/m*∑I{y^(i)!=y(i)},	m是样本数，y^(i)是第i个样本的预测值，I是指示函数。
	做法是，你可以增加把色情图片误分为猫时的权重，更改后的误差率公式为：
		Error=1/∑w(i)*∑ w(i)*I{y^(i)!=y(i)},	w(i)是把色情图片误分为猫时的权重，当没误分类时,w(i)=1,	当误分类时,w(i)=10。
		这里把样本数m换为∑w(i)是为了归一化，这样误差率仍在0和1之间。 									
	当算法将色情图像分类为猫时，误差这个项快速变大。加权的细节并不重要，实际上要使用这种加权，你必须自己过一遍开发集和测试集，
	在开发集和测试集里，自己把色情图片标记出来，这样你才能使用这个加权函数。
	
	如果你发现你的开发测试集都是高质量图像，但是在开发测试集上做的评估，无法预测你的应用实际的表现，因为你的应用处理的是低
	质量图像。那么就应该改变你的开发测试集，让你的数据更能反映你实际需要处理好的数据。
	
	总体方针就是，如果你当前的指标和当前用来评估的数据，跟你真正关心必须做好的事情关系不大，那就应该更改你的指标，或者你的
	开发测试集，让他们能更好的反应你的算法需要处理好的数据。
	
	第一步就要设立目标，第二步是瞄准和射击目标，第三步是最小化训练集上的损失，例如最小化上面的Error。
	将定义评估指标看成第一步，如何优化系统来提高这个指标评分，比如改变你神经网络要优化的成本函数J。

【5】贝叶斯误差与人类水平误差	
	贝叶斯最优误差，也叫贝叶斯误差，一般认为是理论上可能达到的最优误差，就是说没有任何办法设计出一个x到y的函数，让它能够超过
	一定的准确度。贝叶斯最优误差就是从x到y映射的理论最优函数，永远不会被超越。
	
	人类水平误差和贝叶斯最优误差非常接近。
	思考人类水平误差最有用的方式之一是把它作为贝叶斯误差的替代或估计。
	人类水平误差的定义：如果你想要替代或估计贝叶斯误差，那么一队经验丰富的医生讨论和辩论之后可以达到0.5%的误差。我们知道贝
	叶斯误差<=0.5。因为有些系统，这些医生团队可以达到0.5%的误差。根据定义，最优误差必须在0.5%以下，我们不知道多少更好。也许
	有一个更大的团队、更有经验的一声能做的更好，所以也许比0.5%好一点。但是我们知道最优误差不能高于0.5%，那么至少如果你希望
	使用人类水平误差来分析偏差和方差的时候，我就可以用0.5%作为贝叶斯误差，所以我将人类水平定义为0.5%。
	
	训练误差到人类水平误差(或贝叶斯误差估计值)的差距告诉你可避免偏差问题有多大，有多严重；训练误差和开发误差之间的差值告诉
	你方差上的问题有多大，你的算法是否能够从训练集泛化推广到开发集。
	
	今天讲的和之前的课程中的重大区别是，以前你们比较的是训练误差和0%，直接用这个值估计偏差；本视频中，我们有一个更微妙的分析，
	其中并没有假设你应该得到0%误差，因为有时贝叶斯误差是非0的，有时基本不可能做到比某个误差阈值更低。所以在之前的课程中，我们
	测量的是训练误差，然后观察的是训练误差比0%高多少，就用这个差值来估计偏差有多大。而事实证明，对于贝叶斯误差几乎是0%的问题
	这样做很好，例如识别猫，人类表现接近完美，所以贝叶斯误差也接近完美，所以当贝叶斯误差几乎为0时，可以那么做，但数据噪点很多
	时，比如背景声音很嘈杂的语音识别，有时几乎不可能听清说的是什么，并正确记录下来。对于这样的问题，更好的估计贝叶斯误差很有
	必要，可以帮助你更好地估计可避免偏差和方差，这样你就能更好地做出决策，选择减少偏差的策略还是减少方差的策略。这个决策技巧
	通常很有效，直到你的系统性能开始超越人类，那么你对贝叶斯误差的估计就不再准确了。
	
	
	想让一个监督学习算法达到实用，基本上希望或者假设你可以完成两件事情：
	1.首先，你的算法对训练集的拟合很好，这可以看成是，你能做到可避免偏差很低；
	2.在训练集中做得很好，然后推广到开发集和测试集也很好。这就是说，方差不是很大。在正交化的精神下，你可以看到这里有第二组旋钮，
	可以修正可避免偏差问题，比如训练更大的网络，或者训练更久。还有一套独立的技巧可以用来处理方差问题，比如正则化或者收集更多训
	练数据。
	如果你想提升机器学习系统的性能，我建议你们看看训练误差和贝叶斯误差之间的距离，让你知道可避免偏差有多大。换句话说，就是你觉
	得还能做多好，你对训练集的优化还有多少空间。然后看看开发误差和训练误差之间的距离，就知道你的方差问题有多大，换句话说，你应
	该做多少努力，让你的算法表现能够从训练集推广到开发集，算法是没有在开发集上训练的。
	
	人类水平误差与训练误差之间的差值叫可避免误差，减小可避免误差的方法有：使用规模更大的模型、训练更久或使用更好的优化算法（Momen
	-tum，RMApropos，Adam等）、寻找更好的新神经网络架构或者说更好的超参数（改变激活函数、改变层数或者隐藏单元数，或者使用其他架
	构，如循环神经网络和卷积神经网络）。
	
	训练误差到开发误差的差值叫方差，可改变开发误差的方法有：收集更多的数据（因为收集更多的数据去训练，可以帮你更好地推广到系统看
	不到的开发集数据），正则化（L2,dropout,数据增强）、寻找更好的新神经网络架构或者说更好的超参数。
	