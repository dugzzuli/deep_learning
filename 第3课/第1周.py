【1】正交化
	正交意味着互成90度。设计出正交化的控制装置，调整某一(或一组)参数，不会影响到另一(或一组)参数。
	1.首先，你通常必须确保，至少系统在训练集上得到的结果不错，所以训练集上的表现必须通过某种评估达到能接受的程度；
	2.在训练集上表现不错之后，你就希望系统能在开发集上有的表现；
	3.然后你希望系统在测试集上也有好的表现；
	4.在最后，你希望系统在测试集上，系统的成本函数在实际使用中表现令人满意。比如说，你希望这些猫图片应用的用户满意。
【2】单实数评估指标
	查准率(精确率)：在你的分类器标为猫的例子中，有多少真的是猫。如果查准率是95%，这意味着你的分类器说这图有猫的时候，有95%的
			几率真的是猫。
	查全率(召回率)：对于所有真猫的图片，你的分类器正确识别出了多少百分比。实际为猫的图片中，有多少被系统识别出来。
	
	事实证明，查准率和查全率之间往往需要折中，两个指标都要顾及到。你希望得到的效果是，当你的分类器说，某个东西是猫的时候，
	有很大机会它真的是一只猫。但对于所有是猫的图片，你也希望系统能够将大部分分类为猫。所以用查准率和查全率来评估分类器，是
	比较合理的。但使用查准率和查全率作为评估指标的时候，有个问题：如果分类器A在查全率上表现更好，分类器B在查准率上表现更好，
	你就无法判断哪个分类器更好。如果你尝试了很多不同想法，很多不同的超参数，你希望能够快速试验不仅仅是两个分类器，也许是
	十几个分类器，快速选出最好的那个，这样你可以从那里出发再迭代。如果有两个评估指标，就很难去快速地二选一或者十选一。所以
	我并不推荐使用两个评估指标查准率和查全率来选择一个分类器。而是结合查准率和查全率的标准方法，即所谓的F1分数，F1分数的细节
	并不重要，但非正式的，你可以认为这是查准率P和查全率R的平均值；正式来看，F1定义为：F1=2/(1/p+1/R)
	在数学中，这个函数叫做“查准率P和查全率R的调和平均数”。你可以将它堪称是某种查准率和查全率的平均值，只不过你算的不是直接的
	算术平均，而是用上面这个公式的调和均值。这个指标在权衡查准率和查全率时有一些优势。
	
	很多机器学习团队就是这样：有一个定义明确的开发集，用来测量查准率和查全率，再加上这样一个单实数评估指标，能让你快速判断
	哪个算法更好。所以有这样一个开发集，加上一个单实数评估指标，你的迭代速度肯定会很快，它可以加速改进机器学习算法的迭代过程。
	看另一个例子，即当好几个算法对不同国家的误差率也不同时，可以平均每个算法的各个国家的误差率，选取平均误差率最小的算法作为
	最优的算法。
【3】训练集、开发集、测试集划分
	设立训练集、开发集、测试集的方式，大大影响了你或你的团队在建立机器学习应用方面取得进展的速度。
	如何设立开发集和测试集？    
	dev集也叫作开发集，优势称为保留交叉验证集。
	机器学习中的工作流程是，你尝试很多思路，用训练集训练不同的模型，然后开发集来评估不同的思路，然后选择一个，然后不断迭代
	去改善开发集的性能，直到最后你可以得到一个令你满意的成本，然后你在用测试集去评估。
	
	需要保证让测试集和开发集来自同一分布。
	设立你的开发集，加上一个单实数评估指标，这就像是定下目标，然后告诉你的团队，那就是你要瞄准的靶心。因为你一旦建立了这样
	的开发集和指标，团队就可以快速迭代，尝试不同的想法、跑实验，可以很快地使用开发集和指标去评估不同分类器，然后尝试选出最
	好的那个。所以机器学习团队一般都很擅长使用不同方法去逼近目标，然后不断携带，不断逼近靶心。
	
	所以设立开发集和测试集时，如果开发集和测试集数据不来自同一分布，存在一个问题，你的团队可能会花上几个月时间在开发机上迭
	代优化，结果发现，当你们最终在测试集上测试系统时，来自这四个国家的数据和开发集里面的数据可能差异很大。所以你会发现花了
	那么多个月的时间去针对开发集优化，但是最后在测试集上的表现却不佳。所以，如果你的开发集和测试集来自不同的分布，就像你设
	了一个目标，让你的团队花几个月尝试逼近靶心，结果在几个月的工作之后发现不合适。
	方法：将所有数据随机洗牌，放入开发集和测试集，所以开发集和测试集来自同一分布，这分布就是你的所有数据混在一起。
	
	关于设立训练集的方式，会在后面的视频讲到。设立训练集的方式，会影响你逼近那个目标有多快。
